{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key = key, model_name = \"gpt-3.5-turbo\", temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001FE09391AF0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001FE093B76A0>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\bibas\\\\mcq-generator\\\\experiments'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"C:\\Users\\bibas\\mcq-generator\\Response.json\",\"r\") as f:\n",
    "#     RESPONSE_JSON = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'no': '1', 'mcq': 'multiple choice questions', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}, '2': {'no': '2', 'mcq': 'multiple choice questions', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}, '3': {'no': '3', 'mcq': 'multiple choice questions', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}}\n"
     ]
    }
   ],
   "source": [
    "print(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{RESPONSE_JSON}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables = [\"text\",\"number\",\"subject\",\"tone\",\"RESPONSE_JSON\"],\n",
    "    template = TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm = llm, prompt = quiz_generation_prompt, output_key = \"quiz\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables = [\"subject\", \"quiz\"], \n",
    "    template = TEMPLATE2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm = llm, prompt = quiz_evaluation_prompt, output_key=\"review\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain = SequentialChain(chains = [quiz_chain, review_chain], input_variables = [\"text\", \"number\", \"subject\", \"tone\", \"RESPONSE_JSON\"], output_variables = [\"quiz\", \"review\"], verbose = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"C:\\Users\\bibas\\mcq-generator\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bibas\\\\mcq-generator\\\\data.txt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH,\"r\") as file:\n",
    "    TEXT=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent progress in generative models have resulted in models that can produce realistic text, images and video that can potentially revolutionize the way humans work, create content and interact with machines. The workshop on Generative AI at AIMLSystems will focus on the entire life-cycle of building and deploying such Generative AI systems, including data collection and processing, developing systems and requisite infrastructure, applications it enables, and the ethics associated with such technology covering concerns related to fairness, transparency and accountability. We invite original, unpublished work on Artificial Intelligence with a focus on generative AI and their use cases. Specifically, the topics of interest include but are not limited to:\n",
      "\n",
      "Systems, architecture and infrastructure for Generative AI\n",
      "Machine learning and Modeling using LLMs and Diffusion models\n",
      "Large Language Models and its applications\n",
      "Multi-modal Generative AI and its applications\n",
      "Gen AI based Plugins and agents\n",
      "Deployment of Generative AI solutions\n",
      "Evaluation of Language and Diffusion based models\n",
      "Responsible use of Gen AI\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialChain(verbose=True, chains=[LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['RESPONSE_JSON', 'number', 'subject', 'text', 'tone'], template='\\nText:{text}\\nYou are an expert MCQ maker. Given the above text, it is your job to create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \\nMake sure the questions are not repeated and check all the questions to be conforming the text as well.\\nMake sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make {number} MCQs\\n### RESPONSE_JSON\\n{RESPONSE_JSON}\\n\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001FE09391AF0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001FE093B76A0>, openai_api_key='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', openai_proxy=''), output_key='quiz'), LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['quiz', 'subject'], template='\\nYou are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \\nif the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\\nQuiz_MCQs:\\n{quiz}\\n\\nCheck from an expert English Writer of the above quiz:\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001FE09391AF0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001FE093B76A0>, openai_api_key='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', openai_proxy=''), output_key='review')], input_variables=['text', 'number', 'subject', 'tone', 'RESPONSE_JSON'], output_variables=['quiz', 'review'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_evaluate_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent progress in generative models have resulted in models that can produce realistic text, images and video that can potentially revolutionize the way humans work, create content and interact with machines. The workshop on Generative AI at AIMLSystems will focus on the entire life-cycle of building and deploying such Generative AI systems, including data collection and processing, developing systems and requisite infrastructure, applications it enables, and the ethics associated with such technology covering concerns related to fairness, transparency and accountability. We invite original, unpublished work on Artificial Intelligence with a focus on generative AI and their use cases. Specifically, the topics of interest include but are not limited to:\n",
      "\n",
      "Systems, architecture and infrastructure for Generative AI\n",
      "Machine learning and Modeling using LLMs and Diffusion models\n",
      "Large Language Models and its applications\n",
      "Multi-modal Generative AI and its applications\n",
      "Gen AI based Plugins and agents\n",
      "Deployment of Generative AI solutions\n",
      "Evaluation of Language and Diffusion based models\n",
      "Responsible use of Gen AI\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT\n",
    "NUMBER = 4\n",
    "SUBJECT = \"AI\"\n",
    "TONE = \"Simple\",\n",
    "RESPONSE_JSON = RESPONSE_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'no': '1',\n",
       "  'mcq': 'multiple choice questions',\n",
       "  'options': {'a': 'choice here',\n",
       "   'b': 'choice here',\n",
       "   'c': 'choice here',\n",
       "   'd': 'choice here'},\n",
       "  'correct': 'correct answer'},\n",
       " '2': {'no': '2',\n",
       "  'mcq': 'multiple choice questions',\n",
       "  'options': {'a': 'choice here',\n",
       "   'b': 'choice here',\n",
       "   'c': 'choice here',\n",
       "   'd': 'choice here'},\n",
       "  'correct': 'correct answer'},\n",
       " '3': {'no': '3',\n",
       "  'mcq': 'multiple choice questions',\n",
       "  'options': {'a': 'choice here',\n",
       "   'b': 'choice here',\n",
       "   'c': 'choice here',\n",
       "   'd': 'choice here'},\n",
       "  'correct': 'correct answer'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESPONSE_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"no\": \"1\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"no\": \"2\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"no\": \"3\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bibas\\anaconda3\\envs\\mcqGen\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:Recent progress in generative models have resulted in models that can produce realistic text, images and video that can potentially revolutionize the way humans work, create content and interact with machines. The workshop on Generative AI at AIMLSystems will focus on the entire life-cycle of building and deploying such Generative AI systems, including data collection and processing, developing systems and requisite infrastructure, applications it enables, and the ethics associated with such technology covering concerns related to fairness, transparency and accountability. We invite original, unpublished work on Artificial Intelligence with a focus on generative AI and their use cases. Specifically, the topics of interest include but are not limited to:\n",
      "\n",
      "Systems, architecture and infrastructure for Generative AI\n",
      "Machine learning and Modeling using LLMs and Diffusion models\n",
      "Large Language Models and its applications\n",
      "Multi-modal Generative AI and its applications\n",
      "Gen AI based Plugins and agents\n",
      "Deployment of Generative AI solutions\n",
      "Evaluation of Language and Diffusion based models\n",
      "Responsible use of Gen AI\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 4 multiple choice questions for AI students in ('Simple',) tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 4 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"no\": \"1\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"no\": \"2\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"no\": \"3\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for AI students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
      "if the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
      "Quiz_MCQs:\n",
      "{\n",
      "\"1\": {\n",
      "\"no\": \"1\",\n",
      "\"mcq\": \"What is the focus of the workshop on Generative AI at AIMLSystems?\",\n",
      "\"options\": {\n",
      "\"a\": \"Building robots\",\n",
      "\"b\": \"Developing self-driving cars\",\n",
      "\"c\": \"Creating Generative AI systems\",\n",
      "\"d\": \"Testing video games\"\n",
      "},\n",
      "\"correct\": \"c\"\n",
      "},\n",
      "\"2\": {\n",
      "\"no\": \"2\",\n",
      "\"mcq\": \"Which of the following is a topic of interest for the workshop on Generative AI?\",\n",
      "\"options\": {\n",
      "\"a\": \"Building bridges\",\n",
      "\"b\": \"Developing mobile apps\",\n",
      "\"c\": \"Responsible use of Gen AI\",\n",
      "\"d\": \"Cooking recipes\"\n",
      "},\n",
      "\"correct\": \"c\"\n",
      "},\n",
      "\"3\": {\n",
      "\"no\": \"3\",\n",
      "\"mcq\": \"What type of models are used in Machine learning and Modeling for Generative AI?\",\n",
      "\"options\": {\n",
      "\"a\": \"SVM models\",\n",
      "\"b\": \"LLMs and Diffusion models\",\n",
      "\"c\": \"Decision tree models\",\n",
      "\"d\": \"Regression models\"\n",
      "},\n",
      "\"correct\": \"b\"\n",
      "},\n",
      "\"4\": {\n",
      "\"no\": \"4\",\n",
      "\"mcq\": \"What is one of the applications enabled by Large Language Models according to the text?\",\n",
      "\"options\": {\n",
      "\"a\": \"Playing video games\",\n",
      "\"b\": \"Creating realistic text\",\n",
      "\"c\": \"Cooking recipes\",\n",
      "\"d\": \"Building robots\"\n",
      "},\n",
      "\"correct\": \"b\"\n",
      "}\n",
      "}\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with  get_openai_callback() as cb:\n",
    "    response = generate_evaluate_chain(\n",
    "        {\n",
    "\n",
    "        \"text\" : TEXT,\n",
    "        \"number\" : NUMBER,\n",
    "        \"subject\" : SUBJECT,\n",
    "        \"tone\" : TONE,\n",
    "        \"RESPONSE_JSON\" : json.dumps(RESPONSE_JSON)\n",
    "\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:1221\n",
      "Prompt Tokens:879\n",
      "Completion Tokens:342\n",
      "Total Cost:0.0020025\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Recent progress in generative models have resulted in models that can produce realistic text, images and video that can potentially revolutionize the way humans work, create content and interact with machines. The workshop on Generative AI at AIMLSystems will focus on the entire life-cycle of building and deploying such Generative AI systems, including data collection and processing, developing systems and requisite infrastructure, applications it enables, and the ethics associated with such technology covering concerns related to fairness, transparency and accountability. We invite original, unpublished work on Artificial Intelligence with a focus on generative AI and their use cases. Specifically, the topics of interest include but are not limited to:\\n\\nSystems, architecture and infrastructure for Generative AI\\nMachine learning and Modeling using LLMs and Diffusion models\\nLarge Language Models and its applications\\nMulti-modal Generative AI and its applications\\nGen AI based Plugins and agents\\nDeployment of Generative AI solutions\\nEvaluation of Language and Diffusion based models\\nResponsible use of Gen AI',\n",
       " 'number': 4,\n",
       " 'subject': 'AI',\n",
       " 'tone': ('Simple',),\n",
       " 'RESPONSE_JSON': '{\"1\": {\"no\": \"1\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"no\": \"2\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"no\": \"3\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '{\\n\"1\": {\\n\"no\": \"1\",\\n\"mcq\": \"What is the focus of the workshop on Generative AI at AIMLSystems?\",\\n\"options\": {\\n\"a\": \"Building robots\",\\n\"b\": \"Developing self-driving cars\",\\n\"c\": \"Creating Generative AI systems\",\\n\"d\": \"Testing video games\"\\n},\\n\"correct\": \"c\"\\n},\\n\"2\": {\\n\"no\": \"2\",\\n\"mcq\": \"Which of the following is a topic of interest for the workshop on Generative AI?\",\\n\"options\": {\\n\"a\": \"Building bridges\",\\n\"b\": \"Developing mobile apps\",\\n\"c\": \"Responsible use of Gen AI\",\\n\"d\": \"Cooking recipes\"\\n},\\n\"correct\": \"c\"\\n},\\n\"3\": {\\n\"no\": \"3\",\\n\"mcq\": \"What type of models are used in Machine learning and Modeling for Generative AI?\",\\n\"options\": {\\n\"a\": \"SVM models\",\\n\"b\": \"LLMs and Diffusion models\",\\n\"c\": \"Decision tree models\",\\n\"d\": \"Regression models\"\\n},\\n\"correct\": \"b\"\\n},\\n\"4\": {\\n\"no\": \"4\",\\n\"mcq\": \"What is one of the applications enabled by Large Language Models according to the text?\",\\n\"options\": {\\n\"a\": \"Playing video games\",\\n\"b\": \"Creating realistic text\",\\n\"c\": \"Cooking recipes\",\\n\"d\": \"Building robots\"\\n},\\n\"correct\": \"b\"\\n}\\n}',\n",
       " 'review': 'The complexity of the quiz is appropriate for AI students as it tests their knowledge on Generative AI concepts. The questions are clear and concise, focusing on key topics such as model types and applications. No changes are needed.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'no': '1',\n",
       "  'mcq': 'What is the focus of the workshop on Generative AI at AIMLSystems?',\n",
       "  'options': {'a': 'Building robots',\n",
       "   'b': 'Developing self-driving cars',\n",
       "   'c': 'Creating Generative AI systems',\n",
       "   'd': 'Testing video games'},\n",
       "  'correct': 'c'},\n",
       " '2': {'no': '2',\n",
       "  'mcq': 'Which of the following is a topic of interest for the workshop on Generative AI?',\n",
       "  'options': {'a': 'Building bridges',\n",
       "   'b': 'Developing mobile apps',\n",
       "   'c': 'Responsible use of Gen AI',\n",
       "   'd': 'Cooking recipes'},\n",
       "  'correct': 'c'},\n",
       " '3': {'no': '3',\n",
       "  'mcq': 'What type of models are used in Machine learning and Modeling for Generative AI?',\n",
       "  'options': {'a': 'SVM models',\n",
       "   'b': 'LLMs and Diffusion models',\n",
       "   'c': 'Decision tree models',\n",
       "   'd': 'Regression models'},\n",
       "  'correct': 'b'},\n",
       " '4': {'no': '4',\n",
       "  'mcq': 'What is one of the applications enabled by Large Language Models according to the text?',\n",
       "  'options': {'a': 'Playing video games',\n",
       "   'b': 'Creating realistic text',\n",
       "   'c': 'Cooking recipes',\n",
       "   'd': 'Building robots'},\n",
       "  'correct': 'b'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'What is the focus of the workshop on Generative AI at AIMLSystems?',\n",
       "  'Choices': 'a: Building robots | b: Developing self-driving cars | c: Creating Generative AI systems | d: Testing video games',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'Which of the following is a topic of interest for the workshop on Generative AI?',\n",
       "  'Choices': 'a: Building bridges | b: Developing mobile apps | c: Responsible use of Gen AI | d: Cooking recipes',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'What type of models are used in Machine learning and Modeling for Generative AI?',\n",
       "  'Choices': 'a: SVM models | b: LLMs and Diffusion models | c: Decision tree models | d: Regression models',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'What is one of the applications enabled by Large Language Models according to the text?',\n",
       "  'Choices': 'a: Playing video games | b: Creating realistic text | c: Cooking recipes | d: Building robots',\n",
       "  'Correct': 'b'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"genai.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcqGen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
